# FishingStories
Fishing Diary and Predictor

6/8/2022
Database implemented as sql script and generated by sqlalchemy.orm objects.  Plan will be to create an alembic version that 
creates the database, allowing later migrations and rollbacks

As a component of the application, scrapy is used to obtain current data, based on a location.  Implementation considerations
include loading the locations available on the scraped site or to do a k-nearest neighbors analysis on locations in the database
that are near an entered location by the user

Forms are created for adding bait, gear, and angler ranks.  A basic layout is implemented currently, but this can be improved
once functionality is implemented.  Password hashing is explored in a tester and will be utilized in for a complete version.

6/9/2022
Had to ditch scrapy for scraping from websites.  Too much overhead with threading.  Instead, using requests and scrapy.selector
for parsing the html.
Solved the problem of the two forms not posting properly from /fishing_spots.  Had to check that the data for the hidden field
in the view_form is not None.  Also, added the value=spot.name to the hidden file spot_name attribute in the template html.

The web scraping works well, pulling a lot of great data from two web sites.  Need to implement location changing for these.
Also want to implement the entry of coordinates (perhaps from a google map search on a place), from which near by locations
with tidal data can be determined.  
