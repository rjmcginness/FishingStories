# FishingStories
Fishing Diary and Predictor

6/8/2022
Database implemented as sql script and generated by sqlalchemy.orm objects.  Plan will be to create an alembic version that 
creates the database, allowing later migrations and rollbacks

As a component of the application, scrapy is used to obtain current data, based on a location.  Implementation considerations
include loading the locations available on the scraped site or to do a k-nearest neighbors analysis on locations in the database
that are near an entered location by the user

Forms are created for adding bait, gear, and angler ranks.  A basic layout is implemented currently, but this can be improved
once functionality is implemented.  Password hashing is explored in a tester and will be utilized in for a complete version.

6/9/2022
Had to ditch scrapy for scraping from websites.  Too much overhead with threading.  Instead, using requests and scrapy.selector
for parsing the html.
Solved the problem of the two forms not posting properly from /fishing_spots.  Had to check that the data for the hidden field
in the view_form is not None.  Also, added the value=spot.name to the hidden file spot_name attribute in the template html.

The web scraping works well, pulling a lot of great data from two web sites.  Need to implement location changing for these.
Also want to implement the entry of coordinates (perhaps from a google map search on a place), from which near by locations
with tidal data can be determined.

6/11/2022
Fixed bugs with scraping data and transferring it to objects.  Changed the object model in retrieve_tide_current to do this.
Still need to get high, low tide info from retrieve_weather.  Still need to get time zone (ex. EDT) from
retrieve_tide_current.  spot-view.html template renders all of the available data now.  Need to start and finish other
interfaces to completely load interact with db across the model.  Want to implement hashed password authentication.  If time,
may check out OAuth.  To complete, pattern recognition of fishing data related to weather and tide_current data/location.
Would be nice to pretty this up with css and js scripts.

6/13/2022
Major changes to app structure.  Now uses alembic to migrate db, generating initial db from model.  Used duck typing with a
class that faked SQLAlchemy from Flask-SQLAlchemy.  Did this to remain independent from Flask-SQLAlchemy to be able to use
sqlalchemy directly.  Added the requirements.txt file.  Changed initial page to login page.  Added password hashing to UserAccount
class.  Still need to complete implementation of login.  Plan to break apart api more.  Need to test db relations.  I think I have
to add some relations to the models classes to allow for joins.

Login and password hashing is implemented.  Appropriate pages require login.  Still need to implement registration.  Added basic cs
to base.html.

6/14/2022
Login with hashing working.  User registration working, which required the addition of entry of priviledges, account_types, and ranks
to be completed.  Changed css slightly to make the login centered and put a light background on tables to overlay the bocy background.
Tables with class="data-display-table" will do this.  Database with foreign keys and relationships working for Priviledges, AccountType,
UserAccount, Angler, Rank.  Angler may still need some adjustment to relationships with further relations.  
